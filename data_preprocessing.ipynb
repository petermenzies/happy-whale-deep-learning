{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0f1642-7f7c-4f57-b68e-82fd4c6769a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This nb creates a subset of the Happywhale training images and gets them all set up for use with `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00041c7e-0a47-4d44-8c6a-e2cd0de8114e",
   "metadata": {},
   "source": [
    "If we decide to use the full set, it will be easy enough to adapt this code to structure all images for the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bce4a38-95b1-4fe7-acfe-dcae7f6971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11599759-61c5-480d-82c8-f6510de0b719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/courses/EDS232/whales/whales-deep-learning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86e3ca-220e-42fc-a234-a79506e150cb",
   "metadata": {},
   "source": [
    "#### Creating file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd91fc0d-d9db-4a3c-8362-1860411ec4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in csv with image file labels and subsetting into new dfs based on the indices selected above\n",
    "df = pd.read_csv('data/train.csv')\n",
    "image_names = df['image']\n",
    "sp_names = pd.unique(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f229f0b7-a94b-481b-9b9c-88c3c5a00266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train_images/'\n",
    "train_subset_dir = 'data/subset/train_subset/'\n",
    "validation_subset_dir = 'data/subset/validation_subset/'\n",
    "\n",
    "if not os.path.exists(train_subset_dir):\n",
    "\n",
    "    os.mkdir(train_subset_dir)\n",
    "    os.mkdir(validation_subset_dir)\n",
    "\n",
    "    for i in range(0, len(sp_names)):\n",
    "        os.mkdir(train_subset_dir + sp_names[i])\n",
    "        os.mkdir(validation_subset_dir + sp_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2db7e47d-fc2f-4393-afb7-06e9db4f71fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nsamples = len(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9d439c-96b4-4056-84ab-8ba982d691ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly selecting 4000 training images and 1000 validation images\n",
    "seed_value = 71993\n",
    "random.seed(seed_value)\n",
    "sample_indices = random.sample(range(0, train_nsamples), 5000)\n",
    "train_indices = sample_indices[0:4000]\n",
    "validation_indices = sample_indices[4000:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16557f53-feeb-42b4-ad8e-3ef9c0e1beeb",
   "metadata": {},
   "source": [
    "#### Copying files into new directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f170b408-4a0f-4f9b-b061-36b4822cfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_df = df.filter(items = train_indices, axis=0)\n",
    "validation_subset_df = df.filter(items = validation_indices, axis=0)\n",
    "\n",
    "if len(os.listdir(train_subset_dir + sp_names[0]))==0:\n",
    "    \n",
    "    for sp in sp_names:\n",
    "        sp_df = train_subset_df[train_subset_df['species']==sp]\n",
    "\n",
    "        for i in range(0, len(sp_df)):\n",
    "            src = train_dir + sp_df['image'].iloc[i]\n",
    "            dst = train_subset_dir + sp + '/' + sp_df['image'].iloc[i]\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        sp_df = validation_subset_df[validation_subset_df['species']==sp]\n",
    "\n",
    "        for i in range(0, len(sp_df)):\n",
    "            src = train_dir + sp_df['image'].iloc[i]\n",
    "            dst = validation_subset_dir + sp + '/' + sp_df['image'].iloc[i]\n",
    "            shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ed63d-bdf1-4bb2-8991-149360f48d2e",
   "metadata": {},
   "source": [
    "#### Looking at the representation of each species in the subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bd107-6f50-4e8b-8f67-4a462d91eb82",
   "metadata": {},
   "source": [
    "Not super well dispersed, but neither is the full set. We can manually incorporate more of the underrepresented species if we want, but that sounds like a pain.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a72757a-f355-4b3f-bbf7-594be9f61f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melon_headed_whale: 125\n",
      "humpback_whale: 590\n",
      "false_killer_whale: 246\n",
      "bottlenose_dolphin: 738\n",
      "beluga: 606\n",
      "minke_whale: 121\n",
      "fin_whale: 115\n",
      "blue_whale: 357\n",
      "gray_whale: 79\n",
      "southern_right_whale: 73\n",
      "common_dolphin: 28\n",
      "kiler_whale: 85\n",
      "pilot_whale: 18\n",
      "dusky_dolphin: 256\n",
      "killer_whale: 127\n",
      "long_finned_pilot_whale: 15\n",
      "sei_whale: 37\n",
      "spinner_dolphin: 135\n",
      "bottlenose_dolpin: 90\n",
      "cuviers_beaked_whale: 28\n",
      "spotted_dolphin: 35\n",
      "globis: 8\n",
      "brydes_whale: 9\n",
      "commersons_dolphin: 12\n",
      "white_sided_dolphin: 16\n",
      "short_finned_pilot_whale: 30\n",
      "rough_toothed_dolphin: 5\n",
      "pantropic_spotted_dolphin: 8\n",
      "pygmy_killer_whale: 5\n",
      "frasiers_dolphin: 3\n"
     ]
    }
   ],
   "source": [
    "for sp in sp_names:\n",
    "    sp_dir = train_subset_dir + sp\n",
    "    nsamples = len(os.listdir(sp_dir))\n",
    "    print(f'{sp}: {nsamples}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7",
   "language": "python",
   "name": "py3.7.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
